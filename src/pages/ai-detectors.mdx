import MdxLayout from "@/components/mdx-layout";

# A.I. detectors and their flaws

With the rise of artificial intelligence and other language synthesis technologies, there has been a growing problem - how to determine whether or not a piece of text is human-generated or machine-generated. Some tools have been developed to help with this, such as [GPTZero](https://gptzero.me) and [ZeroGPT](https://www.zerogpt.com/). There is one problem with these tools, however, and that is that they are not perfect. In fact, they are far from it.

## How does AI text generation work, exactly?

First, let's take a look at how AI generates responses. AI text generation, such as [ChatGPT](https://chat.openai.com/) and other similar models, operate primarily through [deep learning](https://en.wikipedia.org/wiki/Deep_learning). Let's break down the process into a few steps:

1. **Training**: The AI model is trained on a large dataset of text. This dataset can be anything from books to websites to social media posts. The model learns to generate text by analyzing patterns in the data. [Learn more about training AI models](https://www.oracle.com/artificial-intelligence/ai-model-training/).
2. **Tokenization**: The model tokenizes the input text, breaking it down into individual words or characters. This allows the model to process the text more efficiently. [Learn more about tokenization](<https://en.wikipedia.org/wiki/Tokenization_(lexical_analysis)>).
3. **Generation**: The model generates a response based on the input text. This response is generated by predicting the next word or character in the sequence, based on the patterns it has learned during training. [Learn more about text generation](https://en.wikipedia.org/wiki/Text_generation).
4. **Evaluation**: The generated response is evaluated to determine its quality. This evaluation can be done using various metrics, such as perplexity or BLEU score. [Learn more about text evaluation](https://en.wikipedia.org/wiki/Evaluation_of_machine_translation).
5. **Fine-tuning**: The model is fine-tuned based on the evaluation results, in order to improve its performance. This fine-tuning process can involve adjusting the model's parameters, retraining it on new data, or other techniques. [Learn more about fine-tuning AI models](https://en.wikipedia.org/wiki/Hyperparameter_optimization).
6. **Output**: The final output is generated and presented to the user.

## The flaws

### 1. Bias

One of the biggest flaws of AI detectors is that they are biased. This is because the training data used to train the detectors is often biased itself. For example, if the training data contains a lot of text from a particular demographic, the detector may be more likely to flag text from that demographic as machine-generated. This can lead to unfair discrimination and other negative consequences.

See more:

- [AI Detection Tools Falsely Accuse International Students of Cheating](https://themarkup.org/machine-learning/2023/08/14/ai-detection-tools-falsely-accuse-international-students-of-cheating)
- [ChatGPT Detectors Are Biased and Easy to Fool, Research Shows](https://www.cnet.com/tech/services-and-software/chatgpt-detectors-are-biased-and-easy-to-fool-research-shows/)

### 2. Overfitting

Another flaw of AI detectors is that they are prone to overfitting. Overfitting occurs when a model learns to perform well on the training data, but fails to generalize to new, unseen data. This can happen if the training data is not representative of the real-world data that the model will encounter.

For example, if the training data contains a lot of text from a particular source, the model may learn to perform well on that source, but fail to generalize to other sources. This can lead to false positives and false negatives, where the model incorrectly flags human-generated text as machine-generated, or vice versa.

### 3. You just can't tell

No matter how sophisticated the system, there will always be cases where it fails to accurately detect whether a piece of text is human-generated or machine-generated.

Human language is unique among all forms of life on Earth, and it is extremely difficult to capture all of its nuances and complexities in a statistical model. Key aspects of language such as tone, context, intent, emotion and many others are extremely difficult to capture in a small set of numbers.

Systems such as [GPTZero](https://gptzero.me) use statistical methods to determine whether a piece of text is human-generated or machine-generated. Simply testing text against a predefined statistical model is extremely flawed and completely skips over the nuances of language.

---

Despite these glaring flaws, AI detectors are unfortunately being used in academic settings to determine whether or not students have plagiarized their work. This is problematic for a number of reasons, not least of which is that it unfairly discriminates against students who may have written their work themselves. In recent times, a [Texas professer failed half of his class due to false AI accusations](https://www.businessinsider.com/professor-fails-students-after-chatgpt-falsely-said-it-wrote-papers-2023-5), only exacerbating the problem.

export default function MDXPage({ children }) {
  return (
    <MdxLayout
      metadata={{
        title: "A.I. detectors and their flaws",
        description:
          "Why A.I. detectors are flawed and why they should not be used academically.",
        tags: ["ai", "artificial intelligence", "detectors", "flaws"],
        date: "September 16, 2023",
        authors: [
          {
            name: "Emil Osmicevic",
            avatarUri: "/emil.png",
            email: "emil@solarius.me",
          },
          {
            name: "Ana Đorđević",
            avatarUri: "/ana.jpeg",
            email: "dorda@solarius.me",
          },
          {
            name: "Matt Anderson",
            avatarUri: "/matt.png",
            email: "andem@solarius.me",
          },
        ],
      }}
    >
      {children}
    </MdxLayout>
  );
}
